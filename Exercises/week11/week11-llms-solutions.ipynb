{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10: LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_scaling(logits, temperature=1.0):\n",
    "    probs = torch.softmax(logits / temperature, dim=-1)\n",
    "    return probs\n",
    "\n",
    "def greedy_decoding(probs):\n",
    "    return torch.argmax(probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark on MMLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will benchmark a LLM on the MMLU dataset. We will use the `tinyBenchmarks` dataset which contains a small subset of the MMLU dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load the dataset\n",
    "ds = load_dataset(\"tinyBenchmarks/tinyMMLU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?',\n",
       " 'subject': 'high_school_statistics',\n",
       " 'choices': ['15.4%', '17.8%', '20.0%', '82.1%'],\n",
       " 'answer': 3,\n",
       " 'input_formatted': \"The following are multiple choice questions (with answers) about high school statistics.\\n\\nWhich of the following is a correct statement about correlation?\\nA. If the slope of the regression line is exactly 1, then the correlation is exactly 1.\\nB. If the correlation is 0, then the slope of the regression line is undefined.\\nC. Switching which variable is called x and which is called y changes the sign of the correlation.\\nD. The correlation r is equal to the slope of the regression line when z-scores for the y-variable are plotted against z-scores for the x-variable.\\nAnswer: D\\n\\nSuppose X and Y are random variables with E(X) = 37, var(X) = 5, E(Y) = 62, and var(Y) = 12. What are the expected value and variance of the random variable X + Y?\\nA. E(X + Y) = 99, var(X + Y) = 8.5\\nB. E(X + Y) = 99, var(X + Y) = 13\\nC. E(X + Y) = 99, var(X + Y) = 17\\nD. There is insufficient information to answer this question.\\nAnswer: D\\n\\nAfter a frost warning was issued, the owner of a large orange grove asked his workers to spray all his trees with water. The water was supposed to freeze and form a protective covering of ice around the orange blossom. Nevertheless, the owner suspected that some trees suffered considerable damage due to the frost. To estimate the proportion of trees that suffered more than 50 percent damage due to the frost, he took a random sample of 100 trees from his grove. What is the response variable in this experiment?\\nA. The proportion of trees that suffered more than 50 percent damage due to frost.\\nB. The number of trees affected by the frost.\\nC. The number of trees sampled from the grove.\\nD. For each sampled tree, whether it suffered more than 50 percent damage or at most 50 percent damage.\\nAnswer: D\\n\\nA new smartwatch is manufactured in one part of a factory, then secured for shipping in another, independent part of the factory. The weight of the smartwatch has a mean of 62 grams and a standard deviation of 1.0 grams. The weight of the packaging (box, user's guide, bubble wrap, etc.) has a mean of 456 grams and a standard deviation of 6 grams. Together, the distribution of the weight of the smartwatch and its packaging would have the following mean and standard deviation:\\nA. Mean 518 grams; standard deviation 7.0 grams\\nB. Mean 518 grams; standard deviation 3.5 grams\\nC. Mean 518 grams; standard deviation 6.1 grams\\nD. Mean 394 grams; standard deviation 6.1 grams\\nAnswer: C\\n\\nWhich of the following sets has the smallest standard deviation? Which has the largest?\\nI: {1,2,3}\\nII: {-10,10}\\nIII: {100}\\nA. I, II\\nB. II, III\\nC. III, I\\nD. III, II\\nAnswer: D\\n\\nThe number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?\\nA. 15.4%\\nB. 17.8%\\nC. 20.0%\\nD. 82.1%\\nAnswer:\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first example\n",
    "dataset = ds[\"test\"]\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure each example has 4 choices\n",
    "for sample in dataset:\n",
    "    assert len(sample[\"choices\"]) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to encode each sample into a multiple choice format. Additionally, we need to create a chat template to format the input for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified encode function to create proper chat messages\n",
    "OPTIONS = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "def encode(examples):\n",
    "    inputs = {\"messages\": [], \"label\": []}\n",
    "    for idx, question in enumerate(examples[\"question\"]):\n",
    "        # Format the question and options\n",
    "        text = f\"Question: {question}\\n\"\n",
    "        options = \"\".join([f\"{OPTIONS[i]}: {examples['choices'][idx][i]}\\n\" for i in range(4)])\n",
    "        text += options\n",
    "        text += \"Answer:\"\n",
    "        \n",
    "        # Create chat messages\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "        inputs[\"messages\"].append(messages)\n",
    "        inputs[\"label\"].append(OPTIONS[examples[\"answer\"][idx]])\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cd43a73f5a4aaa825decd1259116f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the map function to apply the encode function to the dataset\n",
    "dataset = dataset.map(encode, batched=True, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?',\n",
       " 'subject': 'high_school_statistics',\n",
       " 'choices': ['15.4%', '17.8%', '20.0%', '82.1%'],\n",
       " 'answer': 3,\n",
       " 'input_formatted': \"The following are multiple choice questions (with answers) about high school statistics.\\n\\nWhich of the following is a correct statement about correlation?\\nA. If the slope of the regression line is exactly 1, then the correlation is exactly 1.\\nB. If the correlation is 0, then the slope of the regression line is undefined.\\nC. Switching which variable is called x and which is called y changes the sign of the correlation.\\nD. The correlation r is equal to the slope of the regression line when z-scores for the y-variable are plotted against z-scores for the x-variable.\\nAnswer: D\\n\\nSuppose X and Y are random variables with E(X) = 37, var(X) = 5, E(Y) = 62, and var(Y) = 12. What are the expected value and variance of the random variable X + Y?\\nA. E(X + Y) = 99, var(X + Y) = 8.5\\nB. E(X + Y) = 99, var(X + Y) = 13\\nC. E(X + Y) = 99, var(X + Y) = 17\\nD. There is insufficient information to answer this question.\\nAnswer: D\\n\\nAfter a frost warning was issued, the owner of a large orange grove asked his workers to spray all his trees with water. The water was supposed to freeze and form a protective covering of ice around the orange blossom. Nevertheless, the owner suspected that some trees suffered considerable damage due to the frost. To estimate the proportion of trees that suffered more than 50 percent damage due to the frost, he took a random sample of 100 trees from his grove. What is the response variable in this experiment?\\nA. The proportion of trees that suffered more than 50 percent damage due to frost.\\nB. The number of trees affected by the frost.\\nC. The number of trees sampled from the grove.\\nD. For each sampled tree, whether it suffered more than 50 percent damage or at most 50 percent damage.\\nAnswer: D\\n\\nA new smartwatch is manufactured in one part of a factory, then secured for shipping in another, independent part of the factory. The weight of the smartwatch has a mean of 62 grams and a standard deviation of 1.0 grams. The weight of the packaging (box, user's guide, bubble wrap, etc.) has a mean of 456 grams and a standard deviation of 6 grams. Together, the distribution of the weight of the smartwatch and its packaging would have the following mean and standard deviation:\\nA. Mean 518 grams; standard deviation 7.0 grams\\nB. Mean 518 grams; standard deviation 3.5 grams\\nC. Mean 518 grams; standard deviation 6.1 grams\\nD. Mean 394 grams; standard deviation 6.1 grams\\nAnswer: C\\n\\nWhich of the following sets has the smallest standard deviation? Which has the largest?\\nI: {1,2,3}\\nII: {-10,10}\\nIII: {100}\\nA. I, II\\nB. II, III\\nC. III, I\\nD. III, II\\nAnswer: D\\n\\nThe number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?\\nA. 15.4%\\nB. 17.8%\\nC. 20.0%\\nD. 82.1%\\nAnswer:\",\n",
       " 'messages': [{'content': 'Question: The number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?\\nA: 15.4%\\nB: 17.8%\\nC: 20.0%\\nD: 82.1%\\nAnswer:',\n",
       "   'role': 'user'}],\n",
       " 'label': 'D'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first example again\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(49152, 2048, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=49152, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a model and tokenizer\n",
    "model_name_or_path = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to apply the chat template to the dataset. We use the tokenizer for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c18502288de422484e94b93f64bf99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply the chat template to the dataset\n",
    "def apply_chat_template(examples):\n",
    "    return {\n",
    "        \"text\": [tokenizer.apply_chat_template(messages, tokenize=False) for messages in examples[\"messages\"]],\n",
    "        \"input_ids\": [tokenizer.apply_chat_template(messages, tokenize=True) for messages in examples[\"messages\"]]\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(apply_chat_template, batched=True, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'The number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?',\n",
       " 'subject': 'high_school_statistics',\n",
       " 'choices': ['15.4%', '17.8%', '20.0%', '82.1%'],\n",
       " 'answer': 3,\n",
       " 'input_formatted': \"The following are multiple choice questions (with answers) about high school statistics.\\n\\nWhich of the following is a correct statement about correlation?\\nA. If the slope of the regression line is exactly 1, then the correlation is exactly 1.\\nB. If the correlation is 0, then the slope of the regression line is undefined.\\nC. Switching which variable is called x and which is called y changes the sign of the correlation.\\nD. The correlation r is equal to the slope of the regression line when z-scores for the y-variable are plotted against z-scores for the x-variable.\\nAnswer: D\\n\\nSuppose X and Y are random variables with E(X) = 37, var(X) = 5, E(Y) = 62, and var(Y) = 12. What are the expected value and variance of the random variable X + Y?\\nA. E(X + Y) = 99, var(X + Y) = 8.5\\nB. E(X + Y) = 99, var(X + Y) = 13\\nC. E(X + Y) = 99, var(X + Y) = 17\\nD. There is insufficient information to answer this question.\\nAnswer: D\\n\\nAfter a frost warning was issued, the owner of a large orange grove asked his workers to spray all his trees with water. The water was supposed to freeze and form a protective covering of ice around the orange blossom. Nevertheless, the owner suspected that some trees suffered considerable damage due to the frost. To estimate the proportion of trees that suffered more than 50 percent damage due to the frost, he took a random sample of 100 trees from his grove. What is the response variable in this experiment?\\nA. The proportion of trees that suffered more than 50 percent damage due to frost.\\nB. The number of trees affected by the frost.\\nC. The number of trees sampled from the grove.\\nD. For each sampled tree, whether it suffered more than 50 percent damage or at most 50 percent damage.\\nAnswer: D\\n\\nA new smartwatch is manufactured in one part of a factory, then secured for shipping in another, independent part of the factory. The weight of the smartwatch has a mean of 62 grams and a standard deviation of 1.0 grams. The weight of the packaging (box, user's guide, bubble wrap, etc.) has a mean of 456 grams and a standard deviation of 6 grams. Together, the distribution of the weight of the smartwatch and its packaging would have the following mean and standard deviation:\\nA. Mean 518 grams; standard deviation 7.0 grams\\nB. Mean 518 grams; standard deviation 3.5 grams\\nC. Mean 518 grams; standard deviation 6.1 grams\\nD. Mean 394 grams; standard deviation 6.1 grams\\nAnswer: C\\n\\nWhich of the following sets has the smallest standard deviation? Which has the largest?\\nI: {1,2,3}\\nII: {-10,10}\\nIII: {100}\\nA. I, II\\nB. II, III\\nC. III, I\\nD. III, II\\nAnswer: D\\n\\nThe number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?\\nA. 15.4%\\nB. 17.8%\\nC. 20.0%\\nD. 82.1%\\nAnswer:\",\n",
       " 'messages': [{'content': 'Question: The number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?\\nA: 15.4%\\nB: 17.8%\\nC: 20.0%\\nD: 82.1%\\nAnswer:',\n",
       "   'role': 'user'}],\n",
       " 'label': 'D',\n",
       " 'text': '<|im_start|>system\\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\\n<|im_start|>user\\nQuestion: The number of days it takes to build a new house has a variance of 386. A sample of 40 new homes shows an average building time of 83 days. With what confidence can we assert that the average building time for a new house is between 80 and 90 days?\\nA: 15.4%\\nB: 17.8%\\nC: 20.0%\\nD: 82.1%\\nAnswer:<|im_end|>\\n',\n",
       " 'input_ids': [1,\n",
       "  9690,\n",
       "  198,\n",
       "  2683,\n",
       "  359,\n",
       "  253,\n",
       "  5356,\n",
       "  5646,\n",
       "  11173,\n",
       "  3365,\n",
       "  3511,\n",
       "  308,\n",
       "  34519,\n",
       "  28,\n",
       "  7018,\n",
       "  411,\n",
       "  407,\n",
       "  19712,\n",
       "  8182,\n",
       "  2,\n",
       "  198,\n",
       "  1,\n",
       "  4093,\n",
       "  198,\n",
       "  17872,\n",
       "  42,\n",
       "  378,\n",
       "  1230,\n",
       "  282,\n",
       "  2009,\n",
       "  357,\n",
       "  2933,\n",
       "  288,\n",
       "  1235,\n",
       "  253,\n",
       "  725,\n",
       "  2291,\n",
       "  553,\n",
       "  253,\n",
       "  17943,\n",
       "  282,\n",
       "  216,\n",
       "  35,\n",
       "  40,\n",
       "  38,\n",
       "  30,\n",
       "  330,\n",
       "  4315,\n",
       "  282,\n",
       "  216,\n",
       "  36,\n",
       "  32,\n",
       "  725,\n",
       "  4711,\n",
       "  2744,\n",
       "  354,\n",
       "  3049,\n",
       "  2194,\n",
       "  655,\n",
       "  282,\n",
       "  216,\n",
       "  40,\n",
       "  35,\n",
       "  2009,\n",
       "  30,\n",
       "  1929,\n",
       "  732,\n",
       "  6204,\n",
       "  416,\n",
       "  392,\n",
       "  2897,\n",
       "  338,\n",
       "  260,\n",
       "  3049,\n",
       "  2194,\n",
       "  655,\n",
       "  327,\n",
       "  253,\n",
       "  725,\n",
       "  2291,\n",
       "  314,\n",
       "  826,\n",
       "  216,\n",
       "  40,\n",
       "  32,\n",
       "  284,\n",
       "  216,\n",
       "  41,\n",
       "  32,\n",
       "  2009,\n",
       "  47,\n",
       "  198,\n",
       "  49,\n",
       "  42,\n",
       "  216,\n",
       "  33,\n",
       "  37,\n",
       "  30,\n",
       "  36,\n",
       "  21,\n",
       "  198,\n",
       "  50,\n",
       "  42,\n",
       "  216,\n",
       "  33,\n",
       "  39,\n",
       "  30,\n",
       "  40,\n",
       "  21,\n",
       "  198,\n",
       "  51,\n",
       "  42,\n",
       "  216,\n",
       "  34,\n",
       "  32,\n",
       "  30,\n",
       "  32,\n",
       "  21,\n",
       "  198,\n",
       "  52,\n",
       "  42,\n",
       "  216,\n",
       "  40,\n",
       "  34,\n",
       "  30,\n",
       "  33,\n",
       "  21,\n",
       "  198,\n",
       "  21350,\n",
       "  42,\n",
       "  2,\n",
       "  198]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first example again\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate predictions for each sample. We will iterate over the dataset one example at a time and generate predictions for each example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating predictions for sample 0\n",
      "Generating predictions for sample 1\n",
      "Generating predictions for sample 2\n",
      "Generating predictions for sample 3\n",
      "Generating predictions for sample 4\n",
      "Generating predictions for sample 5\n"
     ]
    }
   ],
   "source": [
    "# run forward pass\n",
    "N = 5 # we stop after N examples\n",
    "max_tokens = 10 # we generate max_tokens predictions for each example\n",
    "predictions = {} # collect predictions for each sample\n",
    "temperature = 1.0   \n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, sample in enumerate(dataset):\n",
    "        print(\"Generating predictions for sample\", idx)\n",
    "        predictions[idx] = []\n",
    "        input_ids = torch.tensor(sample[\"input_ids\"]).unsqueeze(0)\n",
    "\n",
    "        for _ in range(max_tokens):\n",
    "            \n",
    "            outputs = model.forward(input_ids)\n",
    "            logits = outputs.logits\n",
    "            # get the logits for the last token\n",
    "            logits_last_token = logits[:, -1, :]\n",
    "            logits_last_token.shape\n",
    "\n",
    "            # sample a token from the distribution\n",
    "            probs = temperature_scaling(logits_last_token, temperature=temperature)\n",
    "            preds = greedy_decoding(probs)\n",
    "\n",
    "            # convert prediction to token\n",
    "            preds_tokens = tokenizer.convert_ids_to_tokens(preds.tolist())\n",
    "            predictions[idx].append(preds_tokens)\n",
    "\n",
    "            # append prediction to input_ids\n",
    "            input_ids = torch.cat([input_ids, preds.unsqueeze(0)], dim=1)\n",
    "\n",
    "        if idx >= N:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<|im_start|>'],\n",
       " ['ass'],\n",
       " ['istant'],\n",
       " ['Ċ'],\n",
       " ['C'],\n",
       " [':'],\n",
       " ['Ġ'],\n",
       " ['2'],\n",
       " ['0'],\n",
       " ['.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<|im_start|>'], ['ass'], ['istant'], ['Ċ'], ['C'], [':'], ['Ġ'], ['2'], ['0'], ['.']]\n",
      "D\n",
      "[['<|im_start|>'], ['ass'], ['istant'], ['Ċ'], ['C'], [':'], ['ĠLosing'], ['Ġ'], ['5'], ['-']]\n",
      "C\n",
      "[['<|im_start|>'], ['ass'], ['istant'], ['Ċ'], ['D'], [':'], ['ĠIt'], ['Ġcauses'], ['Ġa'], ['Ġmore']]\n",
      "B\n",
      "[['<|im_start|>'], ['ass'], ['istant'], ['Ċ'], ['D'], [':'], ['ĠIt'], ['Ġis'], ['Ġthe'], ['Ġonly']]\n",
      "B\n",
      "[['<|im_start|>'], ['ass'], ['istant'], ['Ċ'], ['To'], ['Ġsolve'], ['Ġthis'], ['Ġproblem'], [','], ['Ġwe']]\n",
      "C\n",
      "[['<|im_start|>'], ['ass'], ['istant'], ['Ċ'], ['A'], [':'], ['ĠStates'], ['Ġshould'], ['Ġgive'], ['Ġspecial']]\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "accuracies = []\n",
    "for idx in predictions:\n",
    "    preds = predictions[idx]\n",
    "    print(preds)\n",
    "\n",
    "    # get the label for the sample\n",
    "    label = dataset[idx][\"label\"]\n",
    "    print(label)\n",
    "\n",
    "    # did the model predict the correct answer?\n",
    "    correct = int(label in preds)\n",
    "    accuracies.append(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "accuracy = sum(accuracies) / len(accuracies)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
